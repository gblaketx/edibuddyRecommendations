{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import operator\n",
    "from DataLoader import DataLoader\n",
    "from UserMeanEstimator import UserMeanEstimator\n",
    "from RecipeMeanEstimator import RecipeMeanEstimator\n",
    "from LogisticEstimator import LogisticEstimator\n",
    "from PretrainedEstimator import PretrainedEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderPreloaded(DataLoader):\n",
    "    def __init__(self, recipes, all_ratings, recipe_to_raters):\n",
    "        self.recipes = recipes\n",
    "        self.all_ratings = all_ratings\n",
    "        self.recipe_to_raters_test = recipe_to_raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlPreloaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-10f6eda7d03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# import sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlPreloaded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dlPreloaded' is not defined"
     ]
    }
   ],
   "source": [
    "# ratings = pd.read_csv(\"data/all_recipe_clean.csv\")\n",
    "with open(\"data/all_recipes.pkl\", \"rb\") as infile:\n",
    "    recipes = pickle.load(infile) \n",
    "ratings = pd.read_csv(\"data/all_ratings.csv\")\n",
    "dataLoader = DataLoader(ratings, recipes)\n",
    "# user_holdout, recipe_holdout, holdout = dataLoader.get_holdout_data()\n",
    "# holdout_X = [t[:2] for t in holdout]\n",
    "# holdout_Y = np.array([t[2] for t in holdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlPreload = DataLoaderPreloaded(recipes, dataLoader.all_ratings, dataLoader.recipe_to_raters_test)\n",
    "# dlPreload.get_recipe_ratings(272320, None, split=\"test\")\n",
    "# dlPreload.get_user_ratings(1384589, None)\n",
    "# with open(\"data/all_ratings_processed.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(dlPreload.all_ratings, outfile)\n",
    "# dlPreload.all_ratings\n",
    "\n",
    "# with open(\"data/recipe_to_raters.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(dlPreload.recipe_to_raters_test, outfile)\n",
    "\n",
    "# dlPreload.recipe_to_raters_test\n",
    "\n",
    "# sys.getsizeof(recipes)\n",
    "# recipeSt = pickle.dumps(recipes)\n",
    "# sys.getsizeof(recipeSt)\n",
    "\n",
    "# recipes_compressed = {}\n",
    "# for recipe_id, recipe_data in recipes.items():\n",
    "#     ingredients_compressed = {'key ingredients': recipe_data['ingredients']['key ingredients']}\n",
    "#     ingredients_compressed['full list'] = [\n",
    "#         {'quantity': i['quantity'],\n",
    "#          'key ingredient': i['key ingredient']}\n",
    "#         for i in recipe_data['ingredients']['full list']\n",
    "#     ]\n",
    "    \n",
    "#     recipes_compressed[recipe_id] = {\n",
    "#         'calories': recipe_data['calories'],\n",
    "#         'categories': recipe_data['categories'],\n",
    "#         'ingredients': ingredients_compressed,\n",
    "#         'servings': recipe_data['servings'],\n",
    "#         'title': recipe_data['title'],\n",
    "#         'user ratings': recipe_data['user ratings']\n",
    "#     }\n",
    "# recipes_compressed[228101]\n",
    "\n",
    "with open(\"data/recipes_compressed.pkl\", \"wb\") as outfile:\n",
    "    pickle.dump(recipes_compressed, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRecommender:\n",
    "    \"\"\"\n",
    "    \n",
    "    distance: Function that takes in list of recipe_ids selected so far\n",
    "        and target recipe_id and computes the distance between them. Higher\n",
    "        distance scores are considered better for diversity.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 dataLoader, \n",
    "                 estimator, \n",
    "                 diversity_weight=1.0, \n",
    "                 distance = \"cosine\"):\n",
    "        self.estimator = estimator\n",
    "        self.dataLoader = dataLoader\n",
    "        self.recipe_ids = frozenset(dataLoader.get_recipe_ids())\n",
    "        self.diversity_weight = diversity_weight\n",
    "        self.diversity = self.get_diversity_calculation(distance)\n",
    "        self.sim_cache = {}\n",
    "        \n",
    "    def get_diversity_calculation(self, distance):\n",
    "        \"\"\"\n",
    "        Returns the function used to calculate how item new_item would affect the diversity\n",
    "        of recipe set current_items. Higher diversity score is better\n",
    "        \"\"\"\n",
    "        \n",
    "        def average_cosine_similarity(current_items, new_item_id):\n",
    "            sim = 0.0\n",
    "            for recipe_id in current_items:\n",
    "                sim += self.compute_cosine_similiarity(recipe_id, new_item_id)\n",
    "            return -sim / len(current_items)\n",
    "        \n",
    "        def shared_ingredients(current_items, new_item_id):\n",
    "            used_ingredients = { i\n",
    "                                for r_id in current_items\n",
    "                                for i in self.dataLoader.get_recipe_info(r_id)[\"ingredients\"]}\n",
    "            new_recipe_ingredients = { i\n",
    "                                      for i in self.dataLoader.get_recipe_info(new_item_id)[\"ingredients\"]}\n",
    "    \n",
    "            return 1.0 - len(new_recipe_ingredients - used_ingredients) / len(new_recipe_ingredients)\n",
    "    \n",
    "        if distance == \"cosine\":\n",
    "            return average_cosine_similarity\n",
    "        elif distance == \"ingredients\":\n",
    "            return shared_ingredients\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected distance: {}\".format(distance))\n",
    "            \n",
    "    \n",
    "    def compute_cosine_similiarity(self, r1, r2):\n",
    "        key = tuple(sorted([r1, r2]))\n",
    "        if key not in self.sim_cache:\n",
    "            ratings1 = self.dataLoader.get_recipe_ratings(r1, None)\n",
    "            ratings2 = self.dataLoader.get_recipe_ratings(r2, None)\n",
    "            prod = 0\n",
    "            for k in ratings1:\n",
    "                if k in ratings2:\n",
    "                    prod += ratings1[k] * ratings2[k]\n",
    "            self.sim_cache[key] = prod / (len(ratings1) * len(ratings2))\n",
    "        return self.sim_cache[key]\n",
    "\n",
    "\n",
    "    def compute_user_similarity(self, user_ratings1, user_ratings2): \n",
    "        def zero_center_ratings(ratings):\n",
    "            rating_mean = sum(ratings.values()) / len(ratings)\n",
    "            return { rid : value - rating_mean for rid, value in ratings.items() }\n",
    "\n",
    "        def l2_norm(ratings):\n",
    "            return np.linalg.norm(np.fromiter(ratings.values(), dtype=np.float64))\n",
    "\n",
    "        if len(user_ratings1) < 2 or len(user_ratings2) < 2:\n",
    "            return 0.0\n",
    "\n",
    "        prod = 0.0\n",
    "        zero_centered1 = zero_center_ratings(user_ratings1)\n",
    "        zero_centered2 = zero_center_ratings(user_ratings2)\n",
    "        \n",
    "        norm1 = l2_norm(zero_centered1)\n",
    "        norm2 = l2_norm(zero_centered2)\n",
    "        \n",
    "        if norm1 == 0.0 or norm2 == 0.0:\n",
    "            return 0.0\n",
    "        \n",
    "        for k in zero_centered1:\n",
    "            if k in zero_centered2:\n",
    "                prod += zero_centered1[k] * zero_centered2[k]\n",
    "        return prod / (norm1 * norm1)\n",
    "    \n",
    "    def find_similar_user(self, ratings_profile):\n",
    "        potential_users = set()\n",
    "        all_ids = ratings_profile[\"preferred_recipes\"] + ratings_profile[\"non_preferred_recipes\"]\n",
    "        for recipe_id in all_ids:\n",
    "            ratings = self.dataLoader.get_recipe_ratings(recipe_id, None, split=\"test\")\n",
    "            potential_users = potential_users.union(frozenset(ratings.keys()))\n",
    "\n",
    "        ratings_model = {rid: 5.0 for rid in ratings_profile[\"preferred_recipes\"]}\n",
    "        for rid in ratings_profile[\"non_preferred_recipes\"]:\n",
    "            ratings_model[rid] = 3.0\n",
    "\n",
    "        user_similarity = {}\n",
    "        for user_id in potential_users:\n",
    "            user_ratings = self.dataLoader.get_user_ratings(user_id, None)\n",
    "            sim = self.compute_user_similarity(ratings_model, user_ratings)\n",
    "            if sim > 0:\n",
    "                user_similarity[user_id] = sim\n",
    "\n",
    "        return max(user_similarity.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    def get_recommendations(self, ratings_profile, n_recs=100):\n",
    "        user_id = self.find_similar_user(ratings_profile)\n",
    "        preds = self.predict_unrated_recipes(user_id)\n",
    "        return self.select_diverse_recipes(preds, n_recs)\n",
    "        \n",
    "    def predict_unrated_recipes(self, user_id):\n",
    "        \"\"\"\n",
    "        return a sorted list with tuples of recipe id and the user's predicted rating\n",
    "        for all unrated recipes\n",
    "        \"\"\"\n",
    "        user_rated_recipes = frozenset(self.dataLoader.get_user_ratings(user_id, None))\n",
    "        unrated_recipes = self.recipe_ids - user_rated_recipes\n",
    "        X = [(user_id, recipe_id) for recipe_id in unrated_recipes]\n",
    "        predictions = self.estimator.predict(X)\n",
    "        res = []\n",
    "        for i, info in enumerate(X):\n",
    "            _, recipe_id = info\n",
    "            res.append((recipe_id, predictions[i]))\n",
    "        return sorted(res,key=lambda x: -x[1])\n",
    "    \n",
    "    def select_diverse_recipes(self, ratings, n_recs, search_limit=4000):\n",
    "        \"\"\"\n",
    "        ratings: list of (recipe_id, rating) tuples, sorted in descending\n",
    "            order by rating\n",
    "        search_limit: only searches through the top search_limit rated\n",
    "            recipes to make predictions (improves speed)\n",
    "        \"\"\"\n",
    "        if search_limit:\n",
    "            ratings = ratings[:search_limit]\n",
    "        recs = []\n",
    "        original_ratings = {id: rating for id, rating in ratings}\n",
    "        for _ in range(n_recs):\n",
    "            target_recipe_id, _ = ratings.pop(0)\n",
    "            recs.append(target_recipe_id)\n",
    "            new_ratings = []\n",
    "            for i, item in enumerate(ratings):\n",
    "                recipe_id, _ = item\n",
    "                predicted_rating = original_ratings[recipe_id]\n",
    "                revised_score = predicted_rating + self.diversity_weight * self.diversity(recs, recipe_id)\n",
    "                if revised_score == predicted_rating:\n",
    "                    new_ratings = new_ratings + ratings[i:]\n",
    "                    break\n",
    "                new_ratings.append((recipe_id, revised_score))\n",
    "            ratings = sorted(new_ratings, key=lambda x: -x[1])\n",
    "        return recs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: If making a prediction based on an unknown user profile of only ratings, find the most similar user\n",
    "test_ratings_profile = {\n",
    "    \"preferred_recipes\" : [201085, 16806, 154183, 90481, 10387],\n",
    "    \"non_preferred_recipes\" : [11952, 19125, 19211, 51499, 12984]\n",
    "}\n",
    "\n",
    "\n",
    "    \n",
    "# recommender.find_similar_user(test_ratings_profile)    \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: For a given user, run the estimator an all unrated recipes\n",
    "\n",
    "# estimator = RecipeMeanEstimator(dataLoader, defaultdict(set))\n",
    "logitEstimator = LogisticEstimator(dataLoader, None, None)\n",
    "with open(\"models/logit_trained_vec.pkl\", 'rb') as infile:\n",
    "    logitEstimator.vec = pickle.load(infile)\n",
    "with open(\"models/rfcev_trained.pkl\", \"rb\") as infile:\n",
    "    rfecv = pickle.load(infile)\n",
    "\n",
    "estimator = PretrainedEstimator(rfecv, logitEstimator)\n",
    "recommender = RecipeRecommender(dataLoader, estimator, distance=\"ingredients\")\n",
    "# preds_ing = recommender.predict_unrated_recipes(953814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Using the estimates, construct the set that balances diversity and predicted utility\n",
    "# preds_new = recommender.select_diverse_recipes(preds_ing, 100)\n",
    "# preds_old\n",
    "# diversity_metric = recommender.get_diversity_calculation(\"ingredients\")\n",
    "# preds_cos\n",
    "preds_test = recommender.get_recommendations(test_ratings_profile)\n",
    "# len(preds_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[262161,\n",
       " 131107,\n",
       " 262225,\n",
       " 131156,\n",
       " 262229,\n",
       " 262261,\n",
       " 196732,\n",
       " 65663,\n",
       " 262272,\n",
       " 65671,\n",
       " 65686,\n",
       " 131237,\n",
       " 262324,\n",
       " 262326,\n",
       " 65720,\n",
       " 65734,\n",
       " 65759,\n",
       " 262377,\n",
       " 65769,\n",
       " 262392,\n",
       " 262398,\n",
       " 262403,\n",
       " 196879,\n",
       " 262446,\n",
       " 262465,\n",
       " 262468,\n",
       " 262470,\n",
       " 262495,\n",
       " 262496,\n",
       " 262502,\n",
       " 262503,\n",
       " 262510,\n",
       " 221512,\n",
       " 65924,\n",
       " 131523,\n",
       " 197065,\n",
       " 262622,\n",
       " 262647,\n",
       " 131591,\n",
       " 66066,\n",
       " 262717,\n",
       " 197189,\n",
       " 66130,\n",
       " 131668,\n",
       " 262806,\n",
       " 262857,\n",
       " 66294,\n",
       " 262922,\n",
       " 262928,\n",
       " 66326,\n",
       " 131873,\n",
       " 131876,\n",
       " 131891,\n",
       " 66391,\n",
       " 131931,\n",
       " 66396,\n",
       " 263037,\n",
       " 263038,\n",
       " 263054,\n",
       " 66459,\n",
       " 263123,\n",
       " 132065,\n",
       " 132071,\n",
       " 132097,\n",
       " 132109,\n",
       " 132127,\n",
       " 78370,\n",
       " 66646,\n",
       " 66657,\n",
       " 132198,\n",
       " 197751,\n",
       " 263331,\n",
       " 78402,\n",
       " 66782,\n",
       " 263393,\n",
       " 263394,\n",
       " 132326,\n",
       " 132350,\n",
       " 132351,\n",
       " 132358,\n",
       " 132411,\n",
       " 132422,\n",
       " 263498,\n",
       " 263511,\n",
       " 263514,\n",
       " 263521,\n",
       " 91456,\n",
       " 132465,\n",
       " 66933,\n",
       " 263567,\n",
       " 132511,\n",
       " 67002,\n",
       " 263611,\n",
       " 263617,\n",
       " 198099,\n",
       " 67084,\n",
       " 132646,\n",
       " 198182,\n",
       " 263744,\n",
       " 67147]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommender.get_recommendations(36964)\n",
    "# diversity_metric([238270, 240778], 237458)\n",
    "preds_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(preds_cos, preds_ing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset(preds).difference(preds_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11215007691282607"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # preds_new\n",
    "d1 = {'a': 5, 'b': 3, 'c': 4}\n",
    "d2 = {'b': 3, 'c': 5, 'd': 2}\n",
    "\n",
    "# frozenset(d1.keys()).intersection(d2.keys())\n",
    "\n",
    "user_ratings1 = dataLoader.get_user_ratings(138, None)\n",
    "user_ratings2 = dataLoader.get_user_ratings(669128, None)\n",
    "compute_user_similarity(user_ratings1, user_ratings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({7032,\n",
       "           7219,\n",
       "           7567,\n",
       "           8513,\n",
       "           8527,\n",
       "           8537,\n",
       "           8553,\n",
       "           8565,\n",
       "           8568,\n",
       "           8609,\n",
       "           8624,\n",
       "           8890,\n",
       "           8900,\n",
       "           8914,\n",
       "           8993,\n",
       "           9194,\n",
       "           9236,\n",
       "           9253,\n",
       "           9257,\n",
       "           67990,\n",
       "           68330,\n",
       "           68697,\n",
       "           68837,\n",
       "           68879,\n",
       "           69274,\n",
       "           69410,\n",
       "           69865,\n",
       "           69903,\n",
       "           70038,\n",
       "           70163,\n",
       "           70282,\n",
       "           70312,\n",
       "           70343,\n",
       "           70404,\n",
       "           70935,\n",
       "           71422,\n",
       "           71632,\n",
       "           71803,\n",
       "           71891,\n",
       "           72022,\n",
       "           72112,\n",
       "           72636,\n",
       "           72876,\n",
       "           72878,\n",
       "           73177,\n",
       "           73297,\n",
       "           73580,\n",
       "           79518,\n",
       "           132703,\n",
       "           133105,\n",
       "           133633,\n",
       "           134182,\n",
       "           134280,\n",
       "           136846,\n",
       "           138163,\n",
       "           138973,\n",
       "           139291,\n",
       "           139340,\n",
       "           139665,\n",
       "           139917,\n",
       "           140294,\n",
       "           200340,\n",
       "           201117,\n",
       "           202389,\n",
       "           202860,\n",
       "           203248,\n",
       "           204344,\n",
       "           204933,\n",
       "           204952,\n",
       "           222077,\n",
       "           222092,\n",
       "           264155,\n",
       "           265281,\n",
       "           265424,\n",
       "           265521,\n",
       "           265530,\n",
       "           265979,\n",
       "           266343,\n",
       "           266826,\n",
       "           267149,\n",
       "           267247,\n",
       "           268999,\n",
       "           269003,\n",
       "           269763,\n",
       "           270048,\n",
       "           270532,\n",
       "           270721,\n",
       "           271046})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlaps= []\n",
    "\n",
    "# for i, recipe_id in enumerate(preds_test2):\n",
    "#     this_ingredients = frozenset(recipes[recipe_id]['ingredients']['key ingredients'])\n",
    "    \n",
    "#     for other_recipe_id in preds_test[i+1:]:\n",
    "#         other_ingredients = frozenset(recipes[other_recipe_id]['ingredients']['key ingredients'])\n",
    "#         pairwise_overlap = len(this_ingredients.intersection(other_ingredients)) / len(this_ingredients.union(other_ingredients))\n",
    "#         overlaps.append(pairwise_overlap)\n",
    "    \n",
    "# np.mean(overlaps)\n",
    "\n",
    "# for recipe_id in preds_test:\n",
    "#     print(recipes[recipe_id]['title'])\n",
    "# user_ratings1\n",
    "\n",
    "# v1 = np.array([5, 3, 4])\n",
    "# v1 = v1 - np.mean(v1)\n",
    "# v2 = np.array([3, 5, 2])\n",
    "# v2 = v2 - np.mean(v2)\n",
    "\n",
    "# (-1.0 * (-1/3)) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# np.dot(v1[1:], v2[:2])  / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# np.linalg.norm(v2)\n",
    "\n",
    "# find_similar_user(test_ratings_profile)\n",
    "\n",
    "frozenset(preds_test) - frozenset(preds_test3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1854140"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# comp1 = np.random.choice(recipes_10, 5)\n",
    "# comp2 = np.random.choice(recipes_10, 5)\n",
    "# print(comp1, comp2) \n",
    "# target_user_recipes.intersection(dataLoader.get_user_ratings(669128, None).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
